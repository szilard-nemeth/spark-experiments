{
    "Event": "SparkListenerStageSubmitted",
    "Stage Info": {
        "Stage ID": 0,
        "Stage Attempt ID": 0,
        "Stage Name": "count at /app/spark_load.py:23",
        "Number of Tasks": 10,
        "RDD Info": [
            {
                "RDD ID": 1,
                "Name": "PythonRDD",
                "Callsite": "count at /app/spark_load.py:23",
                "Parent IDs": [
                    0
                ],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Use Off Heap": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 10,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            },
            {
                "RDD ID": 0,
                "Name": "ParallelCollectionRDD",
                "Scope": "{\"id\":\"0\",\"name\":\"parallelize\"}",
                "Callsite": "readRDDFromFile at PythonRDD.scala:289",
                "Parent IDs": [],
                "Storage Level": {
                    "Use Disk": false,
                    "Use Memory": false,
                    "Use Off Heap": false,
                    "Deserialized": false,
                    "Replication": 1
                },
                "Barrier": false,
                "DeterministicLevel": "DETERMINATE",
                "Number of Partitions": 10,
                "Number of Cached Partitions": 0,
                "Memory Size": 0,
                "Disk Size": 0
            }
        ],
        "Parent IDs": [],
        "Details": "org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\norg.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\norg.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\njava.base/java.lang.reflect.Method.invoke(Unknown Source)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Unknown Source)",
        "Submission Time": 1765944343120,
        "Accumulables": [],
        "Resource Profile Id": 0,
        "Shuffle Push Enabled": false,
        "Shuffle Push Mergers Count": 0
    },
    "Properties": {
        "spark.rdd.scope": "{\"id\":\"1\",\"name\":\"collect\"}",
        "callSite.short": "count at /app/spark_load.py:23",
        "spark.rdd.scope.noOverride": "true"
    }
}