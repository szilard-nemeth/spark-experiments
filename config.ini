[inventory]
# TODO Need to separate configs that are spark-experiments specific and tool-specific
# TODO Configure inventory with real-world base_url and knox_token
base_url = http://localhost:18080
knox_token = dummy
branch = learn
output_dir = /Users/snemeth/development/cloudera/cde/spark-scale-and-perf/spark-experiments/tool_output/spark_inventory

[profiler]
# TODO event_log_dir must work with HDFS locations as well for BofA's env
event_log_dir = /Users/snemeth/development/cloudera/cde/spark-scale-and-perf/spark-experiments/resources/spark_events
# TODO output_dir must work with HDFS locations as well for BofA's env
output_dir = /Users/snemeth/development/cloudera/cde/spark-scale-and-perf/spark-experiments/tool_output/spark_profiler
branch = learn


[cdp-monitor-pull]

# [CM]
# TODO Prefix-based approach should be replaced with yaml config hierarchy
cm_url=http://ccycloud-1.snemeth.root.comops.site:7180/
cm_cluster_name=Cluster 1
cm_user=admin
cm_pass=admin


# [Dates]
# TODO from_date + to_date should be dynamically passed to the script or determined at runtime
from_date=2025-04-14T00:00:00Z
to_date=2025-04-15T00:00:00Z
limit=1000
scan_time_window = 6

# [Yarn]
service=YARN 1
pool=default
application_types=SPARK

# [Threads]
max_threads = 4

# TODO output_dir must work with HDFS locations as well for BofA's env
output_dir = /Users/snemeth/development/cloudera/cde/spark-scale-and-perf/spark-experiments/tool_output/cdp_monitor_pull
branch = learn
